\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{placeins} % /FloatBarier

\title{Capstone project report -- Inventory Monitoring at Distribution Centers}
\author{Jakub Porebski}

\begin{document}
	\maketitle

\section{Project hyperlinks}
Useful links for the project description:
\begin{itemize}
	\item Github repository: \href{https://github.com/jakpor/Udacity-AWS-ML-project-5}{Udacity-AWS-ML-project-5}
	\item Project proposal document: \href{https://github.com/jakpor/Udacity-AWS-ML-project-5/blob/master/project_proposal/project_proposal.pdf}{project\_proposal/project\_proposal.pdf}
	\item Proposal review: \href{https://review.udacity.com/#!/reviews/3490974}{Review \#3490974}
\end{itemize}

\section{Project Overview}
In modern times logistics and delivery systems are crucial to various parts of the industry. Covid-19 pandemic showed that even short breaks in the logistics chain have huge consequences. Therefore, the big warehouses require reliable and automated system to sort and distribute packages based on multiple characteristics: delivery address, type of material. In these warehouses, packages/objects are usually carried over in boxes, where each box can hold multiple items. The task for the automated delivery system would be to classify the package and determine where to deliver it. But before that the system needs to know how many packages are in each delivery box and that will be the topic of the proposed Capstone project.

In order to count number of objects in a box I would like to make use of \href{https://registry.opendata.aws/amazon-bin-imagery/}{Amazon Bin Image Dataset}, which contain photo of the box content and other objects' characteristics including number of objects. Based on this image the implemented solution will estimate number of objects. 

Similar tasks for counting and characterizing objects in a box can be found in literature e.g. \href{https://arxiv.org/pdf/2107.04852.pdf}{''SynPick: A Dataset for Dynamic Bin Picking Scene Understanding''}

\section{Problem Definition}
In this Section I would like to define the problem to solve and investigate potential solutions and performance metrics.

\subsection{Goal of the project}
The main goal of the project is to create a solution for counting number of objects in each bin base on a photo of the binâ€™s content. The delivered model should have known accuracy in order to predict future false detection rate.

A solution of the project will be a ML model which will be able to determine number of objects in a box based on the photo of the box's content. For the delivered model accuracy will be computed in order to assess the model quality.

\subsection{The datasets and inputs}
For the project I used the \href{https://registry.opendata.aws/amazon-bin-imagery/}{Amazon Bin Image Dataset}. From this dataset I used only around 10000 images labeled with number of items inside a bin. Dataset will be post-processed and divided into train/valid and test subsets.

Amazon description of the dataset: ''The Amazon Bin Image Dataset contains over 500,000 images and metadata from bins of a pod in an operating Amazon Fulfillment Center. The bin images in this dataset are captured as robot units carry pods as part of normal Amazon Fulfillment Center operations.''

Selected subset of around 10000 objects are divided into three subsets for training, test and validation with ratios 60\%-20\%-20\% in corresponding sets. In the selected datasets number of images per class will be balanced, meaning for each class (number of objects in bin) there will be similar number of test/train/validation images. Balancing classes is needed to limit the bias effect in the result network.

\subsection{Baseline model selection}
As a baseline model I would like to use resnet50 image classification network. ResNet-50 is a convolutional neural network that is 50 layers deep. In AWS cloud there is available a pretrained version of the network trained on more than a million images from the \href{http://www.image-net.org}{ImageNet database}. The pretrained network can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many animals. As a result, the network has learned rich feature representations for a wide range of images. The network has an image input size of 224-by-224.

Usage of the pretrained network is justified, because it limits the time needed to get accurate results and the pretrained network has higher change to generalize solution and work on new, not know data.

\subsection{Evaluation Metrics}
The quality of the training process will be evaluated using standard metrics: Cross Entropy Loss function and precision(accuracy). These metrics will measure and quantify the solution and ensure its repeatability for further improvements. For the training procedure a hyper parameter optimization might be needed to ensure that the training process will converge to expected result and won't over-fit to the dataset.

\section{Data analysis}
In this section I will present the overview of the dataset and analyse the problem through visualizations and data exploration to have a better understanding of what algorithms and features are appropriate for solving it.

\subsection{Dataset overview}
The Amazon Bin Image Dataset contains over 500,000 images and metadata from bins of a pod in an operating Amazon Fulfillment Center. In order to limit training time and AWS costs I used provided JSON file with list of 10441 images divided into 5 classes -- with number of items in range $\{1,2,3,4,5\}$.

Sample images from the dataset are presented in Figure~\ref{fig:samples}.
\begin{figure}[ht]
	\centering
	\includegraphics[height=90mm]{../project/sample_dataset_images.png}
	\caption{Sample images from the dataset}
	\label{fig:samples}
\end{figure}

Distribution of images for each class is:
\begin{itemize}
	\item Single object -- $1228$ images -- $12\%$ of the dataset,
	\item Two objects -- $2299$ images -- $22\%$ of the dataset,  
	\item Three objects -- $2666$ images -- $25\%$ of the dataset,  
	\item Four objects -- $2373$ images -- $23\%$ of the dataset,
	\item Five objects -- $1875$ images -- $18\%$ of the dataset,  
\end{itemize}
Number of images for single and five objects in bin are a bit lower than other images, but each class has a representative contribution to the dataset. It is needed to ensure that the model will perform with constant accuracy regardless to the number of objects in bin. If the numbers would deviate much more, the network might not generalize enough to distinguish each class in the dataset.

\subsection{Model selection}
Task of this project is an image classification task. In order to complete it is the best to use pretrained image classification network, which already is able to process and classify some image data. I choose resnet50 network, because I am familiar with the input and output data structures of the network and it is easily available in pytotch models. Other image classification networks might be also appropriate for the task. 

\section{Model implementation}
The project is created in AWS domain using Sagemaker notebooks with some options to limit costs of future development and network training. 
Main steps of the project implementation consist of:
\begin{enumerate}
	\item Data preparation
	\begin{itemize}
		\item fetching data from a database, 
		\item pre-process data and divide it into test, train and validation subsets
		\item upload the data to S3 container
	\end{itemize}	
	\item Model tuning
	\begin{itemize}
		\item tune hyperparameters of the model
		\item train a machine learning model and observe if there are no anomalies in training.
		\item measure KPI metrics, plot training results
	\end{itemize}	
	\item Model deployment
	\begin{itemize}
		\item verify that the model is working as expected
		\item observe the quality of the outcome object
	\end{itemize}
\end{enumerate}
Each part of this procedure will be described in this section.

\subsection{Udacity project requirements}
This is the quote from the project definition in the Udacity course, which was completed in the current project.
\begin{quote}
	To finish this project, you will have to perform the following tasks:
	\begin{enumerate}
		\item Upload Training Data: First you will have to upload the training data to an S3 bucket.
		\item Model Training Script: Once you have done that, you will have to write a script to train a model on that dataset.
		\item Train in SageMaker: Finally, you will have to use SageMaker to run that training script and train your model
	\end{enumerate}
\end{quote}

\subsection{Data preparation}
The downloaded 10441 images had to be divided into train, test and validation subsets. For this project I divided images using 60-20-20 rule:
\begin{itemize}
	\item Train: 60\%
	\item Test: 20\%
	\item Valid: 40\%
\end{itemize}

The network accepts only RGB images with resolution $224\times224$ pixels therefore each image has to be resized and vectorized to match the input layer of the network.

\subsection{Data augmentation}
In the distribution centers bins might be rotated and the network should be able to count the objects regardless of the box rotation. Therefore in the training process I apply random image flipping to ensure that the mirrored images will yield the same results in the network. 

Moreover the network should also count smaller and bigger objects in the bin. Therefore in the resize process I apply random image cropping to ensure that differently scaled images will present the same results.

\subsection{Hyperparameters tuning}
For the tuning procedure I started with a simplified script ''hpo.py'' which executes just a single epoch on a part of training data. This script was used to tune learning rate and batch size hyperparameters in following ranges:
\begin{itemize}
\item Learning rate was tuned for range: $(0.001, 0.1)$ - found optimal value is $0.0011430449671521476$.
\item Batch size was tuned for values: $\{32, 64, 128, 256, 512\}$ - found optimal value is $32$.
\end{itemize}

\subsection{Model training procedure}
After identification of potentially the best hyperparameters I ran training procedure for this task. The code for the training is provided in ''train.py'' file. The file is prepared to be working from Sagemaker notebook (example usage in ''sagemaker.ipynb'') or as a standalone script which can run on your personal machine or on low-cost spot instances. For the $10441$ files the training completed in $3$ epochs after $2$~h of execution.

\section{Model training results}
The ''train.py'' file as prepared to be able to run from both SageMaker Instances and Spot Instances in AWS. In Sagemaker we can access multiple debugging tools to ensure that the training is progressing correctly, but the machines used there are costly. 

\subsection{Sagemaker Instance training}
I run the training in Sagemaker only for a part of the dataset and the Cross Entropy loss function is presented in Figure~\ref{fig:training_sage}.

\begin{figure}[ht]
	\centering
	\includegraphics[height=80mm]{../project/training_debug_values.png}
	\caption{Cross entropy from Sagemaker training}
	\label{fig:training_sage}
\end{figure}

\subsection{Step Instance training}
However, for the full training I went to the ''Step instances'' in order to limit costs of the training process. In ''train.py'' file I have prepared debug prints which allowed me to visualize finalized training process. The same logs can be accessed in SageMaker using AWS CloudWatch service. Loss function and running accuracy plots are presented in Figures~\ref{fig:loss} and \ref{fig:acc} correspondingly.

\begin{figure}[ht]
	\centering
	\includegraphics[height=80mm]{../project/loss.png}
	\caption{Cross entropy loss function changes during the training process.}
	\label{fig:loss}
\end{figure}

\begin{figure}[ht]
	\centering
	\includegraphics[height=80mm]{../project/accuracy.png}
	\caption{Running accuracy of the model through the training}
	\label{fig:acc}
\end{figure}

\FloatBarrier
\subsection{Model deployment}
After generating the trained I heve deployed it as Sagemaker Endpoint and tested it operation on a sample image. For the model inference I have created "inference.py" script, which can be used from Lambda or Sagemaker in AWS. Example code how to deploy the project and run sample inference is provided in ''sagemaker.ipynb'' notebook.

\section{Conclusions}
The final accuracy of the trained model is about $0.3$, which is not the best result. However, considering the fact that I used 5\% of the Amazon Bin Images Dataset and limited the training process to minimum, achieved accuracy is acceptable. In order to improve it however, training on a bigger part of the dataset should be performed. 

During this project I learned how to use AWS cloud to deploy ML solutions following steps:
\begin{enumerate}
	\item Download dataset, preprocess it and store in S3,
	\item Train the network using Sagemaker and Spot istances
	\item Deploy a model as an endpoint and run inference on the model.
\end{enumerate}

\end{document}